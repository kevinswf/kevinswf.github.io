---
title: "Reality Jockey: Lifting the Barrier between Alternate Realities through Audio and Haptic Feedback"
collection: publications
permalink: /publications/RealityJockey
excerpt: "<div style='display: flex; align-items: center;'><img style='float: left; margin-right: 20px; margin-bottom: 10px;' src='/images/realityjockey.png'>Reality Jockey uses audio-haptic cross-modal illusions to create the experience of a past event happening in live."
date: 2013-04-27
venue: "CHI"
paperurl:
citation:
---

<iframe style="width: 100%; aspect-ratio: 16 / 9; border: none; margin-bottom: 1em;" src="https://www.youtube.com/embed/N5gSExZZ2uE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

We present Reality Jockey, a system that confuses the participant's perception of the reality by mixing in a recorded past-reality. The participant will be immersed in a spatialized 3D sound environment that is a mix of sounds from the reality and from the past. The sound environment from the past is augmented with haptic feedback in cross-modality. The haptic feedback is associated with certain sounds such as the vibration in the table when stuff is placed on the table to make the illusion of it happening in live. The seamless transition between live and past creates immersive experience of past events. The blending of live and past allows interactivity. To validate our system, we conducted user studies on 1) does blending live sensations improve such experiences, and 2) how beneficial is it to provide haptic feedbacks in recorded pasts. Potential applications are suggested to illustrate the significance of Reality Jockey.

Kevin Fan, Hideyuki Izumi, Yuta Sugiura, Kouta Minamizawa, Sohei Wakisaka, Masahiko Inami, Naotaka Fujii, and Susumu Tachi. In *Proc. SIGCHI Conference on Human Factors in Computing Systems* (CHI '13). ACM, 2557-2566.